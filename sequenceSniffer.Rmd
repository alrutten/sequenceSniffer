---
title: "duplicate n-gram detection"
author: "Anne Rutten"
date: "January 31, 2020"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### aim:
flag data points that are part of a sequence that is present at least twice in a given data set.


#### sequence flagging:

* function generates n-grams for specified data, iteratively increasing the sequence length from the specified `min_length` until no more duplicate n-grams are present in the data
* data points that are part of an n-gram that is present in the data more than once are marked with an identifier specific to the sequence


#### please note:

* the function does not yet check for overlapping sequences within a specific n-gram length, i.e. a sequence "A A B A A B A" will count and mark n-gram "A A B A" as duplicated
* longer sequences will overwrite shorter sequences that they overlap with, i.e., in the above example, 3-gram "A B A" will be overwritten by 4-gram "A A B A". If "A B A" occurs at a different position as well this may seem an 'orphan' sequence (because its brothers got overwritten by the 4-gram). Likewise, shorter n-grams may be only partly overwritten by a longer n-gram.


```{r, echo=FALSE, message=FALSE }

# helper function: calculate plot height
gg_facet_nrow <- function(p){
  num_panels <- length(unique(ggplot_build(p)$data[[1]]$PANEL)) # get number of panels
  num_cols <- ggplot_build(p)$layout$facet$params$ncol # get number of columns set by user
  num_rows <- wrap_dims(num_panels, ncol=num_cols)[1] # determine number of rows
}
# dependencies
# helper function: install packages when missing

dynamic_require <- function(package){
  # CRAN packages
  if(eval(parse(text=paste("require(",package,")")))) return(TRUE) else
    install.packages(package)
  return(eval(parse(text=paste("require(",package,")"))))
}

deps <- c("tidyverse","ngram", "shiny", "DT", "colorspace")

for (d in deps) dynamic_require(d)

# for test run: Raphaels filename
fn <- "/home/anne/Pardosa_mesocosm_activity_P_R.csv"
```



```{r echo = FALSE}

#### ducttape-and-tiewraps wrapper around `ngram::ngram()`

#* `somevector`: vector of values that needs to be tested for repeat sequences
#* `min_length`: the minimum sequence length
#* `ignoreAllEqual`: ignore n-grams that are repeats of one single value (trying to ignore defaults/censored data/etc)
#* `sep`: in case this is a vector of strings, some separator that is not present in the data itself

findDuplicates <- function(somevector, min_length, ignoreAllEqual=FALSE, sep=" ") {
  # paste all values into one string for n-gram calculation
  values_as_string <- paste(somevector, collapse= sep)

  # input data has to be coverted to character as well
  charactervector <- as.character(somevector)
  output <- data.frame(value=somevector, seqID = NA)
  done <- FALSE
  i <- min_length
  while (!done) {
    duplicates <- get.phrasetable(ngram(values_as_string, i, sep)) %>% 
                   filter(freq>1) %>%
                   select(ngrams) %>%
                   mutate(ngrams = strsplit(ngrams, " ")) # ngram() makes " " separated ngrams.
    
    if (ignoreAllEqual & nrow(duplicates)>0) duplicates <- filter(duplicates, rle(ngrams[[1]])$lengths[[1]]<i)
    if (nrow(duplicates)>0) {
      for(k in 1:nrow(duplicates)) {
        ng <- duplicates$ngrams[[k]]
        idx <- which(charactervector == ng[1])
        seqStart <- idx[sapply(idx, function(j) all(charactervector[j:(j+(length(ng)-1))] == ng))]
        output$seqID[rep(seqStart, each = i) + 0:(i-1)] <-paste0("n",i,"Seq",k)
      }
    }  else done=TRUE
    i<-i+1
 }
 output$seqID
}
 
```

##### example usage in Raphaels data:

download from Raphaels github: https://github.com/rroyaute/Royaute-Pruitt-Ecology-2015-Data-and-Code/blob/master/Data%20files/Pardosa_mesocosm_activity_P_R.csv

### 1: load data

* enter path to your datafile (csv format)

```{r, echo=FALSE}
    inputPanel(
        column(12,textAreaInput("filename", label ="filename: ",value=fn, width = 500
                )))
     inputPanel(actionButton("readRaw", label = "get data"))
```

#### raw data:

* view can be expanded

```{r, echo=FALSE}  

DT::dataTableOutput("rawd")

```

### 2: controls:    

* `focal column range start`: start of column range (including)
* `focal column range end`: end of column range (including)
* `min sequence length`: detect recurring sequences of this length or greater
* `ignore repeats of same value`: in some cases (default values, censored data) many repeat sequences are expected. Check this box to ignore sequences consisting of the same value, repeated.

```{r, echo=FALSE}  
inputPanel(     numericInput("fromColumn", label = "focal column range start: ", value= 3),
                      numericInput("toColumn", label = "focal column range end: ", value=10),
                      br(),
                      numericInput("minGram", label = "min sequence length ", value=4),
                      checkboxInput("ignoreEqual", label = "ignore repeats of same value",  value = FALSE),
                      br(),
                      actionButton("run", label = "detect duplicates")
                
    )
```

### data summary:

* `key`: focal column name
* `cardinality`: number of distinct values in the data
* `max_rle`: longest sequence of repeats of the same number (if high, you may want to select `ignore repeats of same value` above)
* `max_rle_at_level`: the value(s) that is/are repeated `max_rle` times
* `n_duplicates`: number of datapoints that are part of any non-unique sequence of length > `min sequence length`
* `n_total`: number of rows
* `fraction`: `n_duplicates`/`n_total`

```{r, echo=FALSE}  
    DT::dataTableOutput("dataSummary")
```

### detected sequences: 

* view can be expanded
* colours: sequence in column is not unique
* grey: row is not unique
* `value_*` columns: the original data for the focal columna
* `ngramID_*` columns: ngramID of the sequence in the corresponding `value_*` column

`ngramID` is generated as follows: n+`sequence length`+`Sequence ID`. `Sequence ID` does not carry more information.

```{r, echo=FALSE}  

    inputPanel(downloadButton("downloadData","Download csv"))
    DT::dataTableOutput("duplicateNgramsWide")

```

### 3: randomisation controls:

* data will be reordered per column within the grouping levels specified
* **note:** *the order of the selected fields should reflect the data structure.*  
* **caveat** if the assumption that the data points within the applied grouping level are independent of each other is violated (e.g, if the data is a time series and the measured feature is expected to vary with time) this test is relatively meaningless.


```{r, echo=FALSE}  
inputPanel(htmlOutput("groupingVarUI"),
           actionButton("randomiRun", label = "run random reordering")
)

```

### randomisation results:



```{r, echo=FALSE}  

     DT::dataTableOutput("randoTable")
```    


```{r, echo=FALSE, fig.height=30}  

    plotOutput("randoPlot")
```    
  

```{r, echo=FALSE}  
  # load data 
  loadData <- eventReactive(input$readRaw,{
    dataLoaded <- TRUE
     read.csv(input$filename)
    })
  
  output$rawd <- DT::renderDataTable({
    d <- loadData()
   
   datatable(d)
   })
  
  # flag duplicate n-grams
  
  duplicateNgrams <- eventReactive(input$run, {
    d <-loadData()
    d$originalRowID <- row.names(d)
    longd <- gather(d, key, value, input$fromColumn:input$toColumn)
    longd$ngramID <- findDuplicates(longd$value, input$minGram, input$ignoreEqual)
    longd
    })
  
  duplicateNgramsWide <- reactive({
    duplicateNgrams <- duplicateNgrams()
    duplicateNgrams %>% pivot_wider(names_from =key, values_from=c(value, ngramID)) 
  })
  
  observeEvent(input$run, {
    output$duplicateNgramsWide <- DT::renderDataTable({
    duplicateNgrams <- duplicateNgrams()
    duplicateNgramsWide <- duplicateNgramsWide()
    
    
    varnames <- names(duplicateNgramsWide)
    
    ids <- unique(duplicateNgrams$ngramID[!is.na(duplicateNgrams$ngramID)])
    cols <- rainbow_hcl(length(ids))

    varnames <- names(duplicateNgramsWide)
    varsToFormat <- varnames[grepl("value", varnames)]
    varsRef <- varnames[grepl("ngramID", varnames)]
    
    duplicateNgramsWide$duplicatedRow <- duplicated(select_at(duplicateNgramsWide, varsToFormat))|rev(duplicated(select_at(duplicateNgramsWide, varsToFormat) %>% map_df(rev)))
    
    
    ids <- unique(duplicateNgrams$ngramID[!is.na(duplicateNgrams$ngramID)])
    cols <- rainbow_hcl(length(ids))

    datatable(duplicateNgramsWide,
              options = list(
                lengthMenu = list(c(10, 50, -1), c("10","50","All")),
                pageLength=50)
              ) %>%
      formatStyle(varsToFormat, "duplicatedRow", 
              backgroundColor = styleEqual(c(TRUE),"lightgrey")) %>%
      formatStyle(varsToFormat, varsRef, backgroundColor=styleEqual(ids,cols))
  })
  })
  #summary
  dataSummary <-eventReactive(input$run, {
     duplicateNgrams() %>% group_by(key) %>%     
                summarise(cardinality = n_distinct(value),
                          max_rle = with(rle(value) %>% set_names(c("lengths2", "values")), max(lengths2)),
                          max_rle_at_level = if (max_rle>1) with(rle(value) %>% set_names(c("lengths2", "values")), list(unique(values[lengths2==max(lengths2)]))) else list(NA),
                          n_duplicates = sum(!is.na(ngramID)),
                          n_total = n(),
                          fraction = round(n_duplicates/n_total,2)
                          )
    
  })
  output$dataSummary <- DT::renderDataTable({
   dataSummary()
  })
  
  # reactive input for grouping variables
  
  output$groupingVarUI <- renderUI({
      varnames <- names(loadData())
     selectInput("groupingVars", label = "reorder within:", 
                                  choices = varnames, selected =varnames[1],multiple = TRUE)
    
  })
  
  # randomisation test
  
  reorderAndReflag <- eventReactive(input$randomiRun, {
    longd <- duplicateNgrams()

    groupedD <- group_by_at(longd, c(input$groupingVars,"key"))

    res <- list()

   for (i in 1:1000) {
    newd <- groupedD %>%
      mutate(newOrder = runif(n())) %>%
      arrange_at(c(input$groupingVars,"key","newOrder"))
  
      newd$newDupes <- findDuplicates(newd$value, input$minGram, input$ignoreEqual)
      res[[i]] <- group_by(newd, key) %>%
                  summarise(n_duplicates = sum(!is.na(newDupes)))
   }

   resdf <- bind_rows(res) %>%
            mutate(datasource = "simulated") %>%
            bind_rows(select(dataSummary(), key, n_duplicates) %>%
                      mutate(datasource = "actual data"))
 
  })
  
    facetPlotHeight <-reactive({
    gg_facet_nrow(randoPlot())
  })

  randoPlot <- reactive({
    resdf <- reorderAndReflag()
    reflines <- filter(resdf, datasource=="actual data")
    
    ggplot(as.data.frame(resdf), aes(n_duplicates, colour = datasource, fill=datasource)) +
     geom_bar() +
     theme_bw() +
     geom_vline(data=reflines, aes(xintercept = n_duplicates), lty="dashed") +
  theme(legend.position="top") +
  facet_wrap(~key) +
  labs(title = "number of datapoints that are part of a duplicate sequence",
       subtitle =paste("data reordered within:", paste(input$groupingVars, collapse=", "), "\nn_runs=1000; minimum n-gram length =", input$minGram))
  })
  
  randoSummary <- reactive({
    resdf <- reorderAndReflag() %>%
             group_by(key) %>%
             mutate(percentile = rank(n_duplicates)/n()) %>%
             filter(datasource == "actual data")
    
  })
  output$randoTable <- DT::renderDataTable({
    randoSummary()
  })
  
  output$randoPlot <- renderPlot({
     randoPlot()
  }, height = function() {facetPlotHeight() * 300})

  # download handler for flagged data
   output$downloadData <- downloadHandler(
    filename = function() {
      gsub(".csv",input$filename, paste0("_flagged_min_length_",input$minGram,".csv"))
    },
    content = function(file) {
      write.csv(duplicateNgramsWide(), file, row.names = FALSE)
    }
  )

```

